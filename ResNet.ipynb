{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "# A single layer of convolution if shortcut == False, and...\n",
    "# Two layers of convolution and a residual convolution otherwise.\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inChannels, midChannels, outChannels, \n",
    "                 kernelSize, stride = 1, padding = 0, bias = True, shortcut = False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, midChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(midChannels),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(midChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = midChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected block\n",
    "# A single layer if shortcut == False, and...\n",
    "# Two layers and a residual layer otherwise.\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inNodes, midNodes, outNodes, shortcut = False):\n",
    "        super(FCBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, midNodes),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Linear(midNodes, outNodes)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from the given index list. \n",
    "    \"\"\"\n",
    "    def __init__(self, index_list):\n",
    "        self.index = index_list\n",
    "        self.length = len(index_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuDtype = torch.cuda.FloatTensor\n",
    "\n",
    "trainList = []\n",
    "valList = []\n",
    "def checkAccuracy(model, trainLoader, valLoader):\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in trainLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    trainList.append(acc)\n",
    "    print('Train: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    for x, y in valLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    valList.append(acc)\n",
    "    print('Val: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "def train(model, lossFunc, optimizer, numEpochs = 1, \n",
    "          lpReg = {}, lambdaFCB = 0.0,\n",
    "          printEvery = 100, checkEveryEpoch = True):\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, numEpochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainLoader):\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            yVar = Variable(y.type(gpuDtype).long())\n",
    "            scores = model(xVar)            \n",
    "            loss = lossFunc(scores, yVar)\n",
    "            \n",
    "            weights = {}\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'bias' not in name:\n",
    "                    #print(name)\n",
    "                    #print(param)\n",
    "                    weights[name] = param \n",
    "                    for (p, lamb) in lpReg.items():\n",
    "                        loss += lamb * torch.norm(param, int(p))\n",
    "            \n",
    "            #print(weights['blocks.0.left.0.weight'].shape)\n",
    "            #print('Before %f' % loss)\n",
    "            #FCB1WF1dotWS = weights['blocks.5.left.0.weight'].mm(weights['blocks.5.right.0.weight'].t())\n",
    "            #FCB2WF1dotWS = weights['blocks.6.left.0.weight'].mm(weights['blocks.6.right.0.weight'].t())\n",
    "            #loss += lambdaFCB * torch.norm(FCB1WF1dotWS, 2)\n",
    "            #loss += lambdaFCB * torch.norm(FCB2WF1dotWS, 2)\n",
    "            #print('After %f' % loss)\n",
    "            \n",
    "            if printEvery > 0 and (t + 1) % printEvery == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if checkEveryEpoch:\n",
    "            checkAccuracy(model, trainLoader, valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFigure(markLast = 0):\n",
    "    fig = plt.figure(figsize = (15, 8))\n",
    "    NUM_EPOCHS = len(trainList)\n",
    "    pt, = plt.plot(range(1, NUM_EPOCHS + 1), trainList, c = 'red')\n",
    "    pv, = plt.plot(range(1, NUM_EPOCHS + 1), valList, c = 'blue')\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        plt.text(i + 1, trainList[i] + ((i % 2) - 0.8) * 0.005, '%.4f' % trainList[i], ha = 'center', va = 'bottom', fontsize = 9)\n",
    "        plt.text(i + 1, valList[i] + ((i % 2) - 0.8) * 0.005, '%.4f' % valList[i], ha = 'center', va = 'bottom', fontsize = 9)\n",
    "        if markLast > 0 and (i == NUM_EPOCHS - markLast or i == NUM_EPOCHS - 1):\n",
    "            plt.axvline(x = i + 1, color = 'green', linewidth = 2)\n",
    "        else:\n",
    "            plt.axvline(x = i + 1, color = 'lightgrey', linewidth = 1, linestyle = '--')\n",
    "    plt.xticks(range(1, NUM_EPOCHS + 1))\n",
    "    plt.legend([pt, pv], ['Train', 'Val'], loc = 'upper left')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "def showDeltaAcc(numEpochs):\n",
    "    deltaAcc = 0.0\n",
    "    avgValAcc = 0.0\n",
    "    totalEpochs = len(trainList)\n",
    "    for i in range(totalEpochs - numEpochs, totalEpochs):\n",
    "        deltaAcc += trainList[i] - valList[i]\n",
    "        avgValAcc += valList[i]\n",
    "    deltaAcc /= numEpochs\n",
    "    avgValAcc /= numEpochs\n",
    "    print('Delta accuracy of the last %d epochs is: %.4f' % (numEpochs, deltaAcc))\n",
    "    print('Average validation accuracy of the last %d epochs is: %.4f' % (numEpochs, avgValAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ConvBlock(inChannels = 3, midChannels = 9, outChannels = 27, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            ConvBlock(inChannels = 27, midChannels = 81, outChannels = 243, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "            Flatten(),\n",
    "            FCBlock(inNodes = 15552, midNodes = 2592, outNodes = 432, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 432, midNodes = 72, outNodes = 24, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 24, midNodes = 0, outNodes = 10, \n",
    "                    shortcut = False)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 50000\n",
    "\n",
    "numTrain = 20000\n",
    "numVal = 1000\n",
    "\n",
    "#random.seed(666)\n",
    "index_all = random.sample(range(DATASET_SIZE), numTrain + numVal)\n",
    "index_train = index_all[ : numTrain]\n",
    "index_val = index_all[numTrain : ]\n",
    "\n",
    "trainData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, \n",
    "                              sampler = ChunkSampler(index_train))\n",
    "        \n",
    "valData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "valLoader = DataLoader(valData, batch_size = 64, \n",
    "                            sampler = ChunkSampler(index_val))\n",
    "\n",
    "testData = datasets.CIFAR10('./data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "testLoader = DataLoader(testData, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 50\n",
      "Train: 9686 / 20000 correct (48.43%)\n",
      "Val: 443 / 1000 correct (44.30%)\n",
      "Starting epoch 2 / 50\n",
      "Train: 11051 / 20000 correct (55.25%)\n",
      "Val: 503 / 1000 correct (50.30%)\n",
      "Starting epoch 3 / 50\n",
      "Train: 12206 / 20000 correct (61.03%)\n",
      "Val: 531 / 1000 correct (53.10%)\n",
      "Starting epoch 4 / 50\n",
      "Train: 13048 / 20000 correct (65.24%)\n",
      "Val: 559 / 1000 correct (55.90%)\n",
      "Starting epoch 5 / 50\n",
      "Train: 13542 / 20000 correct (67.71%)\n",
      "Val: 572 / 1000 correct (57.20%)\n",
      "Starting epoch 6 / 50\n",
      "Train: 13839 / 20000 correct (69.19%)\n",
      "Val: 553 / 1000 correct (55.30%)\n",
      "Starting epoch 7 / 50\n",
      "Train: 14798 / 20000 correct (73.99%)\n",
      "Val: 582 / 1000 correct (58.20%)\n",
      "Starting epoch 8 / 50\n",
      "Train: 15404 / 20000 correct (77.02%)\n",
      "Val: 606 / 1000 correct (60.60%)\n",
      "Starting epoch 9 / 50\n",
      "Train: 15271 / 20000 correct (76.35%)\n",
      "Val: 605 / 1000 correct (60.50%)\n",
      "Starting epoch 10 / 50\n",
      "Train: 15653 / 20000 correct (78.27%)\n",
      "Val: 601 / 1000 correct (60.10%)\n",
      "Starting epoch 11 / 50\n",
      "Train: 15723 / 20000 correct (78.61%)\n",
      "Val: 601 / 1000 correct (60.10%)\n",
      "Starting epoch 12 / 50\n",
      "Train: 15628 / 20000 correct (78.14%)\n",
      "Val: 587 / 1000 correct (58.70%)\n",
      "Starting epoch 13 / 50\n"
     ]
    }
   ],
   "source": [
    "#TORCH_SEED = 666\n",
    "#torch.manual_seed(TORCH_SEED)\n",
    "#torch.cuda.manual_seed(TORCH_SEED)\n",
    "\n",
    "model = ResNet().type(gpuDtype)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "lpReg = {}\n",
    "train(model, criterion, optimizer, numEpochs = 50, \n",
    "      lpReg = lpReg, lambdaFCB = 0.0,\n",
    "      printEvery = 0, checkEveryEpoch = True)\n",
    "\n",
    "showDeltaAcc(numEpochs = 10)\n",
    "showFigure(markLast = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
