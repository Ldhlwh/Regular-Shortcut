{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "# A single layer of convolution if shortcut == False, and...\n",
    "# Two layers of convolution and a residual convolution otherwise.\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inChannels, midChannels, outChannels, \n",
    "                 kernelSize, stride = 1, padding = 0, bias = True, shortcut = False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, midChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(midChannels),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(midChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected block\n",
    "# A single layer if shortcut == False, and...\n",
    "# Two layers and a residual layer otherwise.\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inNodes, midNodes, outNodes, shortcut = False):\n",
    "        super(FCBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, midNodes),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Linear(midNodes, outNodes)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ChunkSampler(sampler.Sampler):\\n    \"\"\"Samples elements sequentially from some offset. \\n    Arguments:\\n        num_samples: # of desired datapoints\\n        start: offset where we should start selecting from\\n    \"\"\"\\n    def __init__(self, num_samples, start = 0):\\n        self.num_samples = num_samples\\n        self.start = start\\n\\n    def __iter__(self):\\n        return iter(range(self.start, self.start + self.num_samples))\\n\\n    def __len__(self):\\n        return self.num_samples\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from the given index list. \n",
    "    \"\"\"\n",
    "    def __init__(self, index_list):\n",
    "        self.index = index_list\n",
    "        self.length = len(index_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuDtype = torch.cuda.FloatTensor\n",
    "\n",
    "def checkAccuracy(model, trainLoader, valLoader):\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in trainLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    print('Train: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    for x, y in valLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    print('Val: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "def train(model, lossFunc, optimizer, numEpochs = 1, \n",
    "          l1Lambda = 0.0, l2Lambda = 0.0, printEvery = 100, checkEveryEpoch = True):\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, numEpochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainLoader):\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            yVar = Variable(y.type(gpuDtype).long())\n",
    "            scores = model(xVar)            \n",
    "            loss = lossFunc(scores, yVar)\n",
    "            \n",
    "            for name, param in model.named_parameters():\n",
    "                loss += l1Lambda * torch.norm(param, 1) + l2Lambda * torch.norm(param, 2)\n",
    "            \n",
    "            if printEvery > 0 and (t + 1) % printEvery == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if checkEveryEpoch:\n",
    "            checkAccuracy(model, trainLoader, valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ConvBlock(inChannels = 3, midChannels = 8, outChannels = 32, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            ConvBlock(inChannels = 32, midChannels = 128, outChannels = 512, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            FCBlock(inNodes = 32768, midNodes = 4096, outNodes = 512, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 512, midNodes = 128, outNodes = 32, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 32, midNodes = 0, outNodes = 10, \n",
    "                    shortcut = False)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 50000\n",
    "\n",
    "numTrain = 20000\n",
    "numVal = 1000\n",
    "\n",
    "random.seed(666)\n",
    "index_all = random.sample(range(DATASET_SIZE), numTrain + numVal)\n",
    "index_train = index_all[ : numTrain]\n",
    "index_val = index_all[numTrain : ]\n",
    "\n",
    "trainData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, \n",
    "                              sampler = ChunkSampler(index_train))\n",
    "\n",
    "valData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "valLoader = DataLoader(valData, batch_size = 64, \n",
    "                            sampler = ChunkSampler(index_val))\n",
    "\n",
    "testData = datasets.CIFAR10('./data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "testLoader = DataLoader(testData, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 20\n",
      "Train: 5936 / 20000 correct (29.68%)\n",
      "Val: 276 / 1000 correct (27.60%)\n",
      "Starting epoch 2 / 20\n",
      "Train: 7704 / 20000 correct (38.52%)\n",
      "Val: 366 / 1000 correct (36.60%)\n",
      "Starting epoch 3 / 20\n",
      "Train: 10252 / 20000 correct (51.26%)\n",
      "Val: 492 / 1000 correct (49.20%)\n",
      "Starting epoch 4 / 20\n",
      "Train: 12114 / 20000 correct (60.57%)\n",
      "Val: 569 / 1000 correct (56.90%)\n",
      "Starting epoch 5 / 20\n",
      "Train: 12947 / 20000 correct (64.73%)\n",
      "Val: 610 / 1000 correct (61.00%)\n",
      "Starting epoch 6 / 20\n",
      "Train: 14063 / 20000 correct (70.32%)\n",
      "Val: 629 / 1000 correct (62.90%)\n",
      "Starting epoch 7 / 20\n",
      "Train: 14601 / 20000 correct (73.00%)\n",
      "Val: 632 / 1000 correct (63.20%)\n",
      "Starting epoch 8 / 20\n",
      "Train: 15909 / 20000 correct (79.55%)\n",
      "Val: 652 / 1000 correct (65.20%)\n",
      "Starting epoch 9 / 20\n",
      "Train: 16542 / 20000 correct (82.71%)\n",
      "Val: 671 / 1000 correct (67.10%)\n",
      "Starting epoch 10 / 20\n",
      "Train: 16761 / 20000 correct (83.80%)\n",
      "Val: 668 / 1000 correct (66.80%)\n",
      "Starting epoch 11 / 20\n",
      "Train: 17618 / 20000 correct (88.09%)\n",
      "Val: 691 / 1000 correct (69.10%)\n",
      "Starting epoch 12 / 20\n",
      "Train: 17489 / 20000 correct (87.44%)\n",
      "Val: 687 / 1000 correct (68.70%)\n",
      "Starting epoch 13 / 20\n",
      "Train: 18168 / 20000 correct (90.84%)\n",
      "Val: 698 / 1000 correct (69.80%)\n",
      "Starting epoch 14 / 20\n",
      "Train: 17941 / 20000 correct (89.70%)\n",
      "Val: 677 / 1000 correct (67.70%)\n",
      "Starting epoch 15 / 20\n",
      "Train: 18497 / 20000 correct (92.48%)\n",
      "Val: 688 / 1000 correct (68.80%)\n",
      "Starting epoch 16 / 20\n",
      "Train: 18528 / 20000 correct (92.64%)\n",
      "Val: 688 / 1000 correct (68.80%)\n",
      "Starting epoch 17 / 20\n",
      "Train: 18722 / 20000 correct (93.61%)\n",
      "Val: 704 / 1000 correct (70.40%)\n",
      "Starting epoch 18 / 20\n",
      "Train: 18927 / 20000 correct (94.64%)\n",
      "Val: 685 / 1000 correct (68.50%)\n",
      "Starting epoch 19 / 20\n",
      "Train: 18505 / 20000 correct (92.53%)\n",
      "Val: 683 / 1000 correct (68.30%)\n",
      "Starting epoch 20 / 20\n",
      "Train: 18536 / 20000 correct (92.68%)\n",
      "Val: 689 / 1000 correct (68.90%)\n"
     ]
    }
   ],
   "source": [
    "TORCH_SEED = 668\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "torch.cuda.manual_seed(TORCH_SEED)\n",
    "\n",
    "model = ResNet().type(gpuDtype)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "\n",
    "train(model, criterion, optimizer, numEpochs = 20, \n",
    "      l1Lambda = 0.0, l2Lambda = 0.001, \n",
    "      printEvery = 0, checkEveryEpoch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
