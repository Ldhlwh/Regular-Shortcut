{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "# A single layer of convolution if shortcut == False, and...\n",
    "# Two layers of convolution and a residual convolution otherwise.\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inChannels, midChannels, outChannels, \n",
    "                 kernelSize, stride = 1, padding = 0, bias = True, shortcut = False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, midChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(midChannels),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(midChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected block\n",
    "# A single layer if shortcut == False, and...\n",
    "# Two layers and a residual layer otherwise.\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inNodes, midNodes, outNodes, shortcut = False):\n",
    "        super(FCBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, midNodes),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Linear(midNodes, outNodes)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from the given index list. \n",
    "    \"\"\"\n",
    "    def __init__(self, index_list):\n",
    "        self.index = index_list\n",
    "        self.length = len(index_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuDtype = torch.cuda.FloatTensor\n",
    "\n",
    "def checkAccuracy(model, trainLoader, valLoader):\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in trainLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    print('Train: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    for x, y in valLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    print('Val: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "def train(model, lossFunc, optimizer, numEpochs = 1, printEvery = 100, checkEveryEpoch = True):\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, numEpochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainLoader):\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            yVar = Variable(y.type(gpuDtype).long())\n",
    "            scores = model(xVar)            \n",
    "            loss = lossFunc(scores, yVar)\n",
    "            \n",
    "            if printEvery > 0 and (t + 1) % printEvery == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if checkEveryEpoch:\n",
    "            checkAccuracy(model, trainLoader, valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 50000\n",
    "\n",
    "numTrain = 49000\n",
    "numVal = 1000\n",
    "\n",
    "index_all = random.sample(range(DATASET_SIZE), numTrain + numVal)\n",
    "print(index_all[ : 200])\n",
    "index_train = index_all[ : numTrain]\n",
    "index_val = index_all[numTrain : ]\n",
    "\n",
    "print(len(index_train), len(index_val))\n",
    "\n",
    "trainData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, \n",
    "                              sampler = ChunkSampler(index_train)\n",
    "\n",
    "valData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "valLoader = DataLoader(valData, batch_size = 64, \n",
    "                            sampler = ChunkSampler(index_val))\n",
    "\n",
    "testData = datasets.CIFAR10('./data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "testLoader = DataLoader(testData, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ConvBlock(inChannels = 3, midChannels = 8, outChannels = 32, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            ConvBlock(inChannels = 32, midChannels = 128, outChannels = 512, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            FCBlock(inNodes = 32768, midNodes = 4096, outNodes = 512, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 512, midNodes = 128, outNodes = 32, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 32, midNodes = 0, outNodes = 10, \n",
    "                    shortcut = False)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "Train: 92 / 1000 correct (9.20%)\n",
      "Val: 103 / 1000 correct (10.30%)\n",
      "Starting epoch 2 / 10\n",
      "Train: 99 / 1000 correct (9.90%)\n",
      "Val: 113 / 1000 correct (11.30%)\n",
      "Starting epoch 3 / 10\n",
      "Train: 134 / 1000 correct (13.40%)\n",
      "Val: 146 / 1000 correct (14.60%)\n",
      "Starting epoch 4 / 10\n",
      "Train: 142 / 1000 correct (14.20%)\n",
      "Val: 155 / 1000 correct (15.50%)\n",
      "Starting epoch 5 / 10\n",
      "Train: 144 / 1000 correct (14.40%)\n",
      "Val: 158 / 1000 correct (15.80%)\n",
      "Starting epoch 6 / 10\n",
      "Train: 173 / 1000 correct (17.30%)\n",
      "Val: 163 / 1000 correct (16.30%)\n",
      "Starting epoch 7 / 10\n",
      "Train: 174 / 1000 correct (17.40%)\n",
      "Val: 173 / 1000 correct (17.30%)\n",
      "Starting epoch 8 / 10\n",
      "Train: 172 / 1000 correct (17.20%)\n",
      "Val: 163 / 1000 correct (16.30%)\n",
      "Starting epoch 9 / 10\n",
      "Train: 173 / 1000 correct (17.30%)\n",
      "Val: 166 / 1000 correct (16.60%)\n",
      "Starting epoch 10 / 10\n",
      "Train: 174 / 1000 correct (17.40%)\n",
      "Val: 174 / 1000 correct (17.40%)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet().type(gpuDtype)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005, weight_decay = 0.001)\n",
    "\n",
    "train(model, criterion, optimizer, numEpochs = 10, printEvery = 0, checkEveryEpoch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
