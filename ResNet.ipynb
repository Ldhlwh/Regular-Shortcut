{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file) as fo:\n",
    "        dict = pickle.load(fo, encoding-'bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "# A single layer of convolution if shortcut == False, and...\n",
    "# Two layers of convolution and a residual convolution otherwise.\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inChannels, midChannels, outChannels, \n",
    "                 kernelSize, stride = 1, padding = 0, bias = True, shortcut = False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, midChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(midChannels),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(midChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected block\n",
    "# A single layer if shortcut == False, and...\n",
    "# Two layers and a residual layer otherwise.\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inNodes, midNodes, outNodes, shortcut = False):\n",
    "        super(FCBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, midNodes),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Linear(midNodes, outNodes)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ConvBlock(inChannels = 3, midChannels = 8, outChannels = 32, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            #ConvBlock(inChannels = 32, midChannels = 128, outChannels = 512, \n",
    "            #          kernelSize = 3, padding = 1, shortcut = True),\n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            FCBlock(inNodes = 32768, midNodes = 4096, outNodes = 512, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 512, midNodes = 128, outNodes = 64, \n",
    "                    shortcut = True),\n",
    "            \n",
    "            FCBlock(inNodes = 64, midNodes = 0, outNodes = 10, \n",
    "                    shortcut = False)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "numTrain = 49000\n",
    "numVal = 1000\n",
    "\n",
    "trainData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, \n",
    "                              sampler = ChunkSampler(numTrain, 0))\n",
    "\n",
    "valData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "valLoader = DataLoader(valData, batch_size = 64, \n",
    "                            sampler = ChunkSampler(numVal, numTrain))\n",
    "\n",
    "testData = datasets.CIFAR10('./data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "testLoader = DataLoader(testData, batch_size=64)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuDtype = torch.cuda.FloatTensor\n",
    "\n",
    "def train(model, lossFunc, optimizer, numEpochs = 1, printEvery = 100):\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, numEpochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainLoader):\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            yVar = Variable(y.type(gpuDtype).long())\n",
    "            scores = model(xVar)            \n",
    "            loss = lossFunc(scores, yVar)\n",
    "            \n",
    "            if (t + 1) % printEvery == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def checkAccuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        xVar = Variable(x.type(gpuDtype), volatile=True)\n",
    "\n",
    "        scores = model(xVar)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        numCorrect += (preds == y).sum()\n",
    "        numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    print('Got %d / %d correct (%.2f)' % (numCorrect, numSamples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 3\n",
      "t = 100, loss = 2.0931\n",
      "t = 200, loss = 1.8322\n",
      "t = 300, loss = 1.8377\n",
      "t = 400, loss = 1.4903\n",
      "t = 500, loss = 1.3859\n",
      "t = 600, loss = 1.4997\n",
      "t = 700, loss = 1.6152\n",
      "Starting epoch 2 / 3\n",
      "t = 100, loss = 1.3320\n",
      "t = 200, loss = 1.3252\n",
      "t = 300, loss = 1.4243\n",
      "t = 400, loss = 1.1032\n",
      "t = 500, loss = 1.0739\n",
      "t = 600, loss = 1.1613\n",
      "t = 700, loss = 1.3430\n",
      "Starting epoch 3 / 3\n",
      "t = 100, loss = 1.1041\n",
      "t = 200, loss = 1.1149\n",
      "t = 300, loss = 1.2095\n",
      "t = 400, loss = 0.8543\n",
      "t = 500, loss = 0.8849\n",
      "t = 600, loss = 0.8831\n",
      "t = 700, loss = 1.0783\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/lib/python3.5/site-packages/ipykernel_launcher.py:29: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 549 / 1000 correct (54.90)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet().type(gpuDtype)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "train(model, criterion, optimizer, numEpochs = 3, printEvery = 100)\n",
    "checkAccuracy(model, valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
